{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11128734,"sourceType":"datasetVersion","datasetId":6940521},{"sourceId":11129604,"sourceType":"datasetVersion","datasetId":6941166}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install required libraries\n!pip install -q -U google-generativeai\n!pip install -q pandas\n!pip install -q scikit-learn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T16:55:03.911173Z","iopub.execute_input":"2025-03-24T16:55:03.911392Z","iopub.status.idle":"2025-03-24T16:55:29.957912Z","shell.execute_reply.started":"2025-03-24T16:55:03.911371Z","shell.execute_reply":"2025-03-24T16:55:29.957013Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Import libraries\nimport pandas as pd\nimport numpy as np\nimport google.generativeai as genai\nimport json\nimport time\nimport logging\nimport re\n\n# Set up logging\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger(__name__)\n\n# Configure Gemini API\ngenai.configure(api_key=\"AIzaSyAdRIaN-x4kXLRqZG6eszKb558a7WC5-z4\")\n\n# Initialize the Gemini model\nmodel = genai.GenerativeModel('gemini-1.5-flash')\nlogger.info(\"Gemini model initialized.\")\n\n# Define the techniques\ntechniques = [\n    \"loaded_language\", \"euphoria\", \"cherry_picking\", \"bandwagon\", \"glittering_generalities\",\n    \"fud\", \"appeal_to_fear\", \"cliche\", \"whataboutism\", \"straw_man\"\n]\n\n# Load the training dataset to calculate class priors\ntrain_file_path = \"/kaggle/input/unlpdata/NLP - exp(Encoded UTF-8).csv\"\ntrain_df = pd.read_csv(train_file_path)\ntrain_df.columns = train_df.columns.str.strip()\ntrain_df = train_df.applymap(lambda x: x.replace('\\xa0', ' ') if isinstance(x, str) else x)\ntrain_df = train_df.dropna(subset=['content', 'techniques'])\ntrain_df = train_df.reset_index(drop=True)\n\n# Calculate class priors\ntotal_samples = len(train_df)\nclass_counts = {tech: train_df['techniques'].str.contains(tech, na=False).sum() for tech in techniques}\nclass_priors = {tech: count / total_samples for tech, count in class_counts.items()}\nlogger.info(\"Class priors (probability of being 1):\")\nlogger.info(class_priors)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T16:55:29.961409Z","iopub.execute_input":"2025-03-24T16:55:29.961632Z","iopub.status.idle":"2025-03-24T16:55:32.085737Z","shell.execute_reply.started":"2025-03-24T16:55:29.961586Z","shell.execute_reply":"2025-03-24T16:55:32.084894Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-2-e2c876a96e6d>:31: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n  train_df = train_df.applymap(lambda x: x.replace('\\xa0', ' ') if isinstance(x, str) else x)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Load the test dataset \ntest_file_path = \"/kaggle/input/testdatanlp/test-dataunlp.csv\"\ntest_df = pd.read_csv(test_file_path)\ntest_df.columns = test_df.columns.str.strip()\ntest_df = test_df.applymap(lambda x: x.replace('\\xa0', ' ') if isinstance(x, str) else x)\ntest_df = test_df.dropna(subset=['Column2'])\ntest_df = test_df.reset_index(drop=True)\n\n# Adjust to 5735 rows\nlogger.info(f\"Initial test set size: {len(test_df)}\")\nif len(test_df) != 5735:\n    logger.warning(f\"Test set has {len(test_df)} rows, but 5735 rows are required for submission.\")\n    if len(test_df) > 5735:\n        test_df = test_df.iloc[1:].reset_index(drop=True)\n        if len(test_df) > 5735:\n            test_df = test_df.sample(n=5735, random_state=42).reset_index(drop=True)\n        logger.info(f\"Adjusted test set to 5735 rows.\")\n    else:\n        raise ValueError(f\"Test set has only {len(test_df)} rows after adjustments, but 5735 are required.\")\nlogger.info(f\"Final test set size: {len(test_df)}\")\nif len(test_df) != 5735:\n    raise ValueError(f\"Test set has {len(test_df)} rows, but 5735 are required.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T16:55:43.031308Z","iopub.execute_input":"2025-03-24T16:55:43.031623Z","iopub.status.idle":"2025-03-24T16:55:43.298291Z","shell.execute_reply.started":"2025-03-24T16:55:43.031581Z","shell.execute_reply":"2025-03-24T16:55:43.297171Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-3-087d6e32a1c4>:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n  test_df = test_df.applymap(lambda x: x.replace('\\xa0', ' ') if isinstance(x, str) else x)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Preprocessing function\ndef preprocessing(text):\n    text = str(text).strip()\n    text = re.sub(r'\\s+', ' ', text).strip()\n    return text\n\ntest_df['Column2'] = test_df['Column2'].apply(preprocessing)\nlogger.info(\"Test Dataframe Information:\")\ntest_df.info()\n\n# Prepare test set for prediction\ntest_set_sample = test_df.copy()\ntest_set_sample['pred_label'] = ''\n\n# Create batches \nbatch_size = 20\nbatches = []\nfor i in range(0, len(test_set_sample), batch_size):\n    batches.append(test_set_sample[i:i + batch_size])\nlogger.info(f\"Number of batches: {len(batches)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T16:55:45.503104Z","iopub.execute_input":"2025-03-24T16:55:45.503426Z","iopub.status.idle":"2025-03-24T16:55:45.765774Z","shell.execute_reply.started":"2025-03-24T16:55:45.503404Z","shell.execute_reply":"2025-03-24T16:55:45.764939Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 5735 entries, 0 to 5734\nData columns (total 2 columns):\n #   Column   Non-Null Count  Dtype \n---  ------   --------------  ----- \n 0   Column1  5735 non-null   object\n 1   Column2  5735 non-null   object\ndtypes: object(2)\nmemory usage: 89.7+ KB\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Function to process a batch with Gemini (zero-shot )\ndef gemini_completion_function(batch, current_batch, total_batch, model, max_retries=3):\n    logger.info(f\"Now processing batch #{current_batch + 1} of {total_batch}\")\n    \n    json_data = batch[['Column2', 'pred_label']].to_json(orient='records', force_ascii=False)\n\n    prompt = f\"\"\"\n    You are an expert in text analysis and propaganda detection, specializing in Ukrainian and Russian language contexts. Your task is to classify whether each text sample contains specific propaganda techniques. The text samples are primarily in Ukrainian, and they may contain emotionally charged language, cultural references, or wartime rhetoric. Your goal is to identify the presence of the following techniques: loaded_language, euphoria, cherry_picking, bandwagon, glittering_generalities, fud, appeal_to_fear, cliche, whataboutism, straw_man. For each sample, output a list of 10 binary labels (0 or 1) corresponding to the presence of each technique in the order listed above. A text can contain multiple techniques, so carefully analyze the content for all possibilities.\n\n    ### Definitions and Examples of Techniques\n    - **loaded_language**: Using emotionally charged words to influence the audience.\n      Example: \"Военкомы продолжают паковать украинцев в микроавтобусы, пока нардепы только хотят рассмотреть нарушения в мобилизационном треке.\" (Transliteration: \"Voenkomy prodolzhayut pakovat' ukraintsev v mikroavtobusy...\") This uses \"паковать украинцев\" (packing Ukrainians) to evoke a strong emotional response.\n    - **euphoria**: Highlighting positive events to boost morale and create optimism.\n      Example: \"Наши влупили на 3 направлениях, 3 переправы организовали – все успешные.\" (Transliteration: \"Nashi vlupili na 3 napravleniyakh...\") This creates a celebratory tone about military success.\n    - **cherry_picking**: Selectively presenting data to support a claim while ignoring counterarguments.\n      Example: \"По нашим данным военкомы Одесской, Полтавской... почти перевыполняют план по мобилизации.\" (Transliteration: \"Po nashim dannym voenkomy Odesskoy, Poltavskoy...\") This highlights over-fulfillment in some areas while ignoring under-fulfillment elsewhere.\n    - **bandwagon**: Suggesting that everyone is doing something, so you should too.\n      Example: \"В Германии набирает тренд санкционный скептицизм...\" (Transliteration: \"V Germanii nabiraet trend sanktsionnyy skeptitsizm...\") This implies a growing trend to join.\n    - **glittering_generalities**: Using vague, positive words like \"freedom\" or \"justice\" to evoke emotions.\n      Example: \"Дорогі українці! Сьогодні ми всі – єдині, як ніколи... Слава Україні!\" (Transliteration: \"Dorohi ukrayintsi! S'ohodni my vsi – yedyni, yak nikoly... Slava Ukrayini!\") This uses \"єдині\" (united) and \"Слава Україні\" (Glory to Ukraine) to evoke patriotism.\n    - **fud**: Spreading fear, uncertainty, and doubt.\n      Example: \"Останню бригаду кинули в бій, резервів не залишилось...\" (Transliteration: \"Ostan'nyu bryhadu kynuly v biy, rezerviv ne zalyshylos'...\") This raises doubt about military resources.\n    - **appeal_to_fear**: Using fear to persuade.\n      Example: \"УКРАЇНЦІВ ЗМУСЯТЬ СТАТИ НА ОБЛІК ЗА КОРДОНОМ? ... можуть вимкнутись навіть банківські картки.\" (Transliteration: \"UKRAYINTSIV ZMUSYAT' STATY NA OBLІK ZA KORDONOM?...\") This creates fear of losing banking access.\n    - **cliche**: Using overused phrases to block critical thinking.\n      Example: \"Всієї правди ми ніколи не дізнаємось.\" (Transliteration: \"Vsiyeyi pravdy my nikoly ne diznayemos'.\") This cliché dismisses further inquiry.\n    - **whataboutism**: Deflecting criticism by pointing to another issue.\n      Example: \"ВСУ выпустили точку-У, россияне её сбили... Такая же ситуация была в Одессе...\" (Transliteration: \"VSU vypustili tochku-U, rossiyane yeyo sbili...\") This shifts focus to a similar incident.\n    - **straw_man**: Misrepresenting an opponent’s argument to make it easier to attack.\n      Example: \"Согласно с меморандумом МОН... внедрения в образовательный процесс «гендерно чувствительных методов обучения»...\" (Transliteration: \"Zhidno z memorandumom MON...\") This exaggerates the policy as harmful to children.\n\n    ### Guidelines for Classification\n    - A text can have multiple techniques. For example, a text might use both \"loaded_language\" and \"appeal_to_fear\" if it contains emotionally charged words and evokes fear.\n    - Be cautious with rare techniques like \"straw_man\" or \"bandwagon\". They are less common, but if the text fits the definition, mark them as 1.\n    - If a technique is not present, mark it as 0. Avoid overpredicting 1s, but also avoid always predicting 0 for rare classes.\n    - Pay attention to the Ukrainian context. Words like \"Слава Україні\" (Glory to Ukraine) often indicate \"glittering_generalities\", while phrases like \"мясорубка\" (meat grinder) might indicate \"loaded_language\".\n\n    ### Task\n    Classify the following text samples provided in JSON format. For each sample, analyze the text in the 'Column2' field and update the 'pred_label' field with a string of 10 space-separated binary labels (e.g., \"1 0 0 0 0 0 0 0 0 0\"). Return the JSON data with updated 'pred_label' values—do not change the format.\n\n    {json_data}\n    \"\"\"\n\n    for attempt in range(max_retries):\n        try:\n            response = model.generate_content(prompt)\n            raw_response = response.text.strip()\n            cleaned_json = raw_response.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n            json.loads(cleaned_json)\n            return cleaned_json\n        except Exception as e:\n            logger.error(f\"Error in batch {current_batch + 1}, attempt {attempt + 1}/{max_retries}: {e}\")\n            if attempt == max_retries - 1:\n                logger.warning(f\"Max retries reached for W batch {current_batch + 1}. Using default predictions.\")\n                batch['pred_label'] = \"0 0 0 0 0 0 0 0 0 0\"\n                return batch[['Column2', 'pred_label']].to_json(orient='records', force_ascii=False)\n            time.sleep(5 * (attempt + 1))\n\n# Process all batches\nbatch_count = len(batches)\nresponses = []\nfor i in range(batch_count):\n    print(f\"Starting batch #{i + 1} of {batch_count}\")  # Added print statement\n    response = gemini_completion_function(batches[i], i, batch_count, model)\n    responses.append(response)\n    time.sleep(3)  # Reduced delay\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T16:57:28.248748Z","iopub.execute_input":"2025-03-24T16:57:28.249066Z","iopub.status.idle":"2025-03-24T19:28:44.706018Z","shell.execute_reply.started":"2025-03-24T16:57:28.249045Z","shell.execute_reply":"2025-03-24T19:28:44.705016Z"}},"outputs":[{"name":"stdout","text":"Starting batch #1 of 287\nStarting batch #2 of 287\nStarting batch #3 of 287\nStarting batch #4 of 287\nStarting batch #5 of 287\nStarting batch #6 of 287\nStarting batch #7 of 287\nStarting batch #8 of 287\nStarting batch #9 of 287\nStarting batch #10 of 287\nStarting batch #11 of 287\nStarting batch #12 of 287\nStarting batch #13 of 287\nStarting batch #14 of 287\nStarting batch #15 of 287\nStarting batch #16 of 287\nStarting batch #17 of 287\nStarting batch #18 of 287\nStarting batch #19 of 287\nStarting batch #20 of 287\nStarting batch #21 of 287\nStarting batch #22 of 287\nStarting batch #23 of 287\nStarting batch #24 of 287\nStarting batch #25 of 287\nStarting batch #26 of 287\nStarting batch #27 of 287\nStarting batch #28 of 287\nStarting batch #29 of 287\nStarting batch #30 of 287\nStarting batch #31 of 287\nStarting batch #32 of 287\nStarting batch #33 of 287\nStarting batch #34 of 287\nStarting batch #35 of 287\nStarting batch #36 of 287\nStarting batch #37 of 287\nStarting batch #38 of 287\nStarting batch #39 of 287\nStarting batch #40 of 287\nStarting batch #41 of 287\nStarting batch #42 of 287\nStarting batch #43 of 287\nStarting batch #44 of 287\nStarting batch #45 of 287\nStarting batch #46 of 287\nStarting batch #47 of 287\nStarting batch #48 of 287\nStarting batch #49 of 287\nStarting batch #50 of 287\nStarting batch #51 of 287\nStarting batch #52 of 287\nStarting batch #53 of 287\nStarting batch #54 of 287\nStarting batch #55 of 287\nStarting batch #56 of 287\nStarting batch #57 of 287\nStarting batch #58 of 287\nStarting batch #59 of 287\nStarting batch #60 of 287\nStarting batch #61 of 287\nStarting batch #62 of 287\nStarting batch #63 of 287\nStarting batch #64 of 287\nStarting batch #65 of 287\nStarting batch #66 of 287\nStarting batch #67 of 287\nStarting batch #68 of 287\nStarting batch #69 of 287\nStarting batch #70 of 287\nStarting batch #71 of 287\nStarting batch #72 of 287\nStarting batch #73 of 287\nStarting batch #74 of 287\nStarting batch #75 of 287\nStarting batch #76 of 287\nStarting batch #77 of 287\nStarting batch #78 of 287\nStarting batch #79 of 287\nStarting batch #80 of 287\nStarting batch #81 of 287\nStarting batch #82 of 287\nStarting batch #83 of 287\nStarting batch #84 of 287\nStarting batch #85 of 287\nStarting batch #86 of 287\nStarting batch #87 of 287\nStarting batch #88 of 287\nStarting batch #89 of 287\nStarting batch #90 of 287\nStarting batch #91 of 287\nStarting batch #92 of 287\nStarting batch #93 of 287\nStarting batch #94 of 287\nStarting batch #95 of 287\nStarting batch #96 of 287\nStarting batch #97 of 287\nStarting batch #98 of 287\nStarting batch #99 of 287\nStarting batch #100 of 287\nStarting batch #101 of 287\nStarting batch #102 of 287\nStarting batch #103 of 287\nStarting batch #104 of 287\nStarting batch #105 of 287\nStarting batch #106 of 287\nStarting batch #107 of 287\nStarting batch #108 of 287\nStarting batch #109 of 287\nStarting batch #110 of 287\nStarting batch #111 of 287\nStarting batch #112 of 287\nStarting batch #113 of 287\nStarting batch #114 of 287\nStarting batch #115 of 287\nStarting batch #116 of 287\nStarting batch #117 of 287\nStarting batch #118 of 287\nStarting batch #119 of 287\nStarting batch #120 of 287\nStarting batch #121 of 287\nStarting batch #122 of 287\nStarting batch #123 of 287\nStarting batch #124 of 287\nStarting batch #125 of 287\nStarting batch #126 of 287\nStarting batch #127 of 287\nStarting batch #128 of 287\nStarting batch #129 of 287\nStarting batch #130 of 287\nStarting batch #131 of 287\nStarting batch #132 of 287\nStarting batch #133 of 287\nStarting batch #134 of 287\nStarting batch #135 of 287\nStarting batch #136 of 287\nStarting batch #137 of 287\nStarting batch #138 of 287\nStarting batch #139 of 287\nStarting batch #140 of 287\nStarting batch #141 of 287\nStarting batch #142 of 287\nStarting batch #143 of 287\nStarting batch #144 of 287\nStarting batch #145 of 287\nStarting batch #146 of 287\nStarting batch #147 of 287\nStarting batch #148 of 287\nStarting batch #149 of 287\nStarting batch #150 of 287\nStarting batch #151 of 287\nStarting batch #152 of 287\nStarting batch #153 of 287\nStarting batch #154 of 287\nStarting batch #155 of 287\nStarting batch #156 of 287\nStarting batch #157 of 287\nStarting batch #158 of 287\nStarting batch #159 of 287\nStarting batch #160 of 287\nStarting batch #161 of 287\nStarting batch #162 of 287\nStarting batch #163 of 287\nStarting batch #164 of 287\nStarting batch #165 of 287\nStarting batch #166 of 287\nStarting batch #167 of 287\nStarting batch #168 of 287\nStarting batch #169 of 287\nStarting batch #170 of 287\nStarting batch #171 of 287\nStarting batch #172 of 287\nStarting batch #173 of 287\nStarting batch #174 of 287\nStarting batch #175 of 287\nStarting batch #176 of 287\nStarting batch #177 of 287\nStarting batch #178 of 287\nStarting batch #179 of 287\nStarting batch #180 of 287\nStarting batch #181 of 287\nStarting batch #182 of 287\nStarting batch #183 of 287\nStarting batch #184 of 287\nStarting batch #185 of 287\nStarting batch #186 of 287\nStarting batch #187 of 287\nStarting batch #188 of 287\nStarting batch #189 of 287\nStarting batch #190 of 287\nStarting batch #191 of 287\nStarting batch #192 of 287\nStarting batch #193 of 287\nStarting batch #194 of 287\nStarting batch #195 of 287\nStarting batch #196 of 287\nStarting batch #197 of 287\nStarting batch #198 of 287\nStarting batch #199 of 287\nStarting batch #200 of 287\nStarting batch #201 of 287\nStarting batch #202 of 287\nStarting batch #203 of 287\nStarting batch #204 of 287\nStarting batch #205 of 287\nStarting batch #206 of 287\nStarting batch #207 of 287\nStarting batch #208 of 287\nStarting batch #209 of 287\nStarting batch #210 of 287\nStarting batch #211 of 287\nStarting batch #212 of 287\nStarting batch #213 of 287\nStarting batch #214 of 287\nStarting batch #215 of 287\nStarting batch #216 of 287\nStarting batch #217 of 287\nStarting batch #218 of 287\nStarting batch #219 of 287\nStarting batch #220 of 287\nStarting batch #221 of 287\nStarting batch #222 of 287\nStarting batch #223 of 287\nStarting batch #224 of 287\nStarting batch #225 of 287\nStarting batch #226 of 287\nStarting batch #227 of 287\nStarting batch #228 of 287\nStarting batch #229 of 287\nStarting batch #230 of 287\nStarting batch #231 of 287\nStarting batch #232 of 287\nStarting batch #233 of 287\nStarting batch #234 of 287\nStarting batch #235 of 287\nStarting batch #236 of 287\nStarting batch #237 of 287\nStarting batch #238 of 287\nStarting batch #239 of 287\nStarting batch #240 of 287\nStarting batch #241 of 287\nStarting batch #242 of 287\nStarting batch #243 of 287\nStarting batch #244 of 287\nStarting batch #245 of 287\nStarting batch #246 of 287\nStarting batch #247 of 287\nStarting batch #248 of 287\nStarting batch #249 of 287\nStarting batch #250 of 287\nStarting batch #251 of 287\nStarting batch #252 of 287\nStarting batch #253 of 287\nStarting batch #254 of 287\nStarting batch #255 of 287\nStarting batch #256 of 287\nStarting batch #257 of 287\nStarting batch #258 of 287\nStarting batch #259 of 287\nStarting batch #260 of 287\nStarting batch #261 of 287\nStarting batch #262 of 287\nStarting batch #263 of 287\nStarting batch #264 of 287\nStarting batch #265 of 287\nStarting batch #266 of 287\nStarting batch #267 of 287\nStarting batch #268 of 287\nStarting batch #269 of 287\nStarting batch #270 of 287\nStarting batch #271 of 287\nStarting batch #272 of 287\nStarting batch #273 of 287\nStarting batch #274 of 287\nStarting batch #275 of 287\nStarting batch #276 of 287\nStarting batch #277 of 287\nStarting batch #278 of 287\nStarting batch #279 of 287\nStarting batch #280 of 287\nStarting batch #281 of 287\nStarting batch #282 of 287\nStarting batch #283 of 287\nStarting batch #284 of 287\nStarting batch #285 of 287\nStarting batch #286 of 287\nStarting batch #287 of 287\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Combine all responses into a single DataFrame\ndf_total = pd.DataFrame()\nfor idx, response in enumerate(responses):\n    try:\n        json_data = response.strip(\"`\")\n        data = json.loads(json_data)\n        df_temp = pd.DataFrame(data)\n        df_total = pd.concat([df_total, df_temp], ignore_index=True)\n    except json.JSONDecodeError as e:\n        logger.error(f\"JSON decode error in batch {idx + 1}: {e}\")\n        batch_size = len(batches[idx])\n        default_data = [{\"Column2\": \"\", \"pred_label\": \"0 0 0 0 0 0 0 0 0 0\"} for _ in range(batch_size)]\n        df_temp = pd.DataFrame(default_data)\n        df_total = pd.concat([df_total, df_temp], ignore_index=True)\n\n# Parse the pred_label strings into separate columns\npred_labels = df_total['pred_label'].apply(lambda x: [int(i) for i in x.split()]).tolist()\npred_df = pd.DataFrame(pred_labels, columns=techniques)\n\ntest_set_sample[techniques] = pred_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T19:59:48.851451Z","iopub.status.idle":"2025-03-24T19:59:48.851772Z","shell.execute_reply":"2025-03-24T19:59:48.851636Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Post-process predictions using class priors\nadjusted_preds = test_set_sample[techniques].copy()\nfor tech in techniques:\n    prob = class_priors[tech]\n    current_ones = adjusted_preds[tech].sum()\n    target_ones = int(prob * len(test_set_sample))\n    if current_ones < target_ones:\n        zero_indices = adjusted_preds[adjusted_preds[tech] == 0].index\n        num_to_flip = target_ones - current_ones\n        if num_to_flip > 0 and len(zero_indices) > 0:\n            flip_indices = np.random.choice(zero_indices, size=min(num_to_flip, len(zero_indices)), replace=False)\n            adjusted_preds.loc[flip_indices, tech] = 1\n    elif current_ones > target_ones:\n        one_indices = adjusted_preds[adjusted_preds[tech] == 1].index\n        num_to_flip = current_ones - target_ones\n        if num_to_flip > 0 and len(one_indices) > 0:\n            flip_indices = np.random.choice(one_indices, size=min(num_to_flip, len(one_indices)), replace=False)\n            adjusted_preds.loc[flip_indices, tech] = 0\n\n# Update test_set_sample with adjusted predictions\ntest_set_sample[techniques] = adjusted_preds.astype(int)\n\nlogger.info(\"Number of 1s per technique after adjustment:\")\nlogger.info(test_set_sample[techniques].sum())\n\n# Create submission file\nsubmission = test_set_sample[['Column1']].copy()\nsubmission.columns = ['id']\nsubmission[techniques] = test_set_sample[techniques].astype(int)\n\nlogger.info(f\"Number of data rows in submission (excluding header): {len(submission)}\")\nif len(submission) != 5735:\n    raise ValueError(f\"Submission has {len(submission)} data rows, but 5735 are required.\")\n\nsubmission.to_csv(\"submission_gemini_improved.csv\", index=False)\nlogger.info(\"Submission file created: submission_gemini_improved.csv\")\nlogger.info(\"First few rows of submission:\")\nlogger.info(submission.head().to_string())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T19:29:13.974082Z","iopub.execute_input":"2025-03-24T19:29:13.974387Z","iopub.status.idle":"2025-03-24T19:29:14.036248Z","shell.execute_reply.started":"2025-03-24T19:29:13.974361Z","shell.execute_reply":"2025-03-24T19:29:14.035607Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
